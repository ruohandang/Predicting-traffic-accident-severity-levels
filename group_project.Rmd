---
title: "group_project"
author: "RuohanDang"
date: "6/12/2020"
output: html_document

params:
  filename1: US_Accidents_Dec19.csv
---
```{r}
##############
## Library ##
##############
library(tidyverse)
library(lubridate)

##########################################
## Import dataset and check ##
##########################################
US_Accidents <- read.csv(params$filename1, header = TRUE)
head(US_Accidents,5)
str(US_Accidents)
summary(US_Accidents)
dim(US_Accidents)
# [1] 2974335      49

##########################################
## Data Preprocessing for EDA ##
##########################################
## Deal with variables
# 1. remove variables with high NA proportion and not useful variables
# variables with NA proportion larger than 50% cannot give enough information to our analysis.
US_Accidents %>% summarise_all(~ mean(is.na(.))) %>% 
  pivot_longer(1:49, names_to = "Variables to drop", values_to = "NA proportion") %>% 
  filter(`NA proportion` >= 0.5)
# so we drop these five variables:
# End_Lat, End_Lng, Number, Wind_Chill.F., Precipitation.in.
na_cols <- c("End_Lat", "End_Lng", "Number", "Wind_Chill.F.", "Precipitation.in.")
# there are some variables will not give us insights about traffic accidents 
# or be useful in predicting severity levels
not_useful <- c("ID", "Source", "Description", "Timezone", "Airport_Code", "Weather_Timestamp", "Wind_Direction")

data_drop <- US_Accidents %>% 
  select(-all_of(na_cols), -all_of(not_useful))

dim(data_drop)
# 2974335 observations and 37 variables now

# 2. location related variables
# There are several variables indicating the location of the accident. 
# Apart from the accurate coordinate, longitude and latitude, 
# the dataset also contains state, city, county and even street address. 
# However, we want to find some nationwide patterns or statewide patterns from this dataset.
# So we can romove them now.
address <- c("Country", "City", "County", "Street", "Zipcode")

data_drop %>%
  select(all_of(address)) %>%
  head(5)

data_US <- data_drop %>% 
  select(-all_of(address))

dim(data_US)
#  2974335      32

# 3. transform time variables
# Time variables are in a format that is difficult to manipulate in the original dataset,
# so we transform two time variables to some new variables can reflect like hourly, weekly or monthly patterns.
data_US <- data_US %>%
  separate(Start_Time, into = c("Date", "Time"), sep = " ") %>%
  mutate("Year" = str_sub(Date, 1, 4), "Month" = str_sub(Date, 6, 7), "Day" = str_sub(Date, 9, 10), 
         "Wday" = as.character(wday(Date)), "Hour" = str_sub(Time, 1, 2)) %>%
  select(-c("Date", "Time", "End_Time")) %>%
  select(TMC, Severity, Year, Month, Day, Hour, Wday, everything())
# after transformation
data_US %>%
  select(Year, Month, Day, Hour, Wday) %>%
  head(5)

dim(data_US)
# 2974335      35

# 4. TMC variable problem
# check the relationship betweet TMC and Severity
data_US %>% 
  ggplot(aes(factor(TMC), ..prop..)) +
  geom_bar(aes(group = Severity, fill = factor(Severity)), show.legend = F) +
  facet_wrap(~ Severity, scales = "free") +
  labs(x = "TMC",
       y = "Proportion",
       title = "TMC distribution in each severity level") +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.6),
        legend.position = "top") +
  scale_fill_brewer(palette = "Set1")
# we find NA value is an important feature of severity level 4, 
# so we decide to treat NA value as a new level of TMC.
data_US <- data_US %>% 
  mutate(TMC = replace_na(TMC, "NA_TMC"))

# 5. weather condition NA problems
# we can remove all records containing this variable's NA value because all weather variables are related
data_US$Weather_Condition[data_US$Weather_Condition==""] <- "NA"
sum(is.na(data_US$Weather_Condition))

data_US <- data_US %>% 
  filter(!is.na(Weather_Condition))

dim(data_US)
#  2908403      35

# 6. other missing values
summary(data_US)
str(data_US)
# there are still some records containing NA values in continuous variables
# we can replace these NA values with the mean of the corresponding variable
data_US <- data_US %>%
  mutate_if(is.numeric, ~ replace_na(., mean(., na.rm = T)))

sum(is.na(data_US))
# 0
# save a tidy data
write_csv(data_US, "tidydata_US.csv")

############################
## Visualization ##
############################
# set correct type to each variable
data_US <- data_US %>% 
  type_convert() %>%
  mutate(TMC = factor(TMC), Severity = factor(Severity), Year = factor(Year), Wday = factor(Wday)) %>%
  mutate_if(is.logical, factor) %>%
  mutate_if(is.character, factor)

# 1. Accident count
# states with maximum number of accidents
data_US %>%
  select(State) %>%
  group_by(State) %>%
  summarise(AccdtCount = sum(duplicated(State))) %>%
  arrange(desc(AccdtCount)) %>%
  ggplot(aes(x=State, y=AccdtCount)) + 
  geom_col(color= "grey")

# 2. Accident count in each severity level
data_US %>%
  group_by(Year, Severity) %>%
  count() %>%
  group_by(Year) %>%
  mutate(sum = sum(n)) %>%
  mutate(Proportion = n / sum) %>%
  ggplot(aes(Severity, Proportion)) +
  geom_col(aes(fill = Year), position = "dodge") +
  labs(x = "Severity",
       y = "Proportion",
       title = "Severity proportion changes by year") 

# 3. Accident account in different months
data_US %>%
  count(Month) %>%
  ggplot(aes(Month, n)) +
  geom_line(aes(group = 1)) +
  geom_point() +
  labs(y = "Count",
       x = NULL,
       title = "Pattern between accident counts and month") +
  scale_x_discrete(labels = c("Jan", "Feb", "Mar", "Apr", "May",
                              "Jun", "Jul", "Aug", "Sep", "Oct",
                              "Nov", "Dec")) 
# 4. Accident account in different day of the week
data_US %>%
  count(Wday) %>%
  ggplot(aes(Wday, n, fill = Wday)) +
  geom_bar(position="dodge",stat = "identity") +
  geom_point() +
  labs(y = "Count",
       x = NULL,
       title = "Pattern between accident counts and day of the week") +
  scale_x_discrete(labels = c("Mon", "Tue", "Wed", "Thr", "Fri",
                              "Sat", "Sun")) 
# 5. Accident account in different hour of day
data_US %>%
  ggplot(aes(Hour, fill = !Hour %in% c("07", "08", "16", "17"))) +
  geom_bar(show.legend = F) +
  labs(x = "Hour",
       y = "No of Accidents",
       title = "Hourly Distribution of Accidents")

# 6. Weather with Accident
Weather <- data_US %>% group_by(Weather_Condition) %>% count()

Weather_data <- data.frame(
  name=c("Clear", "Haze" , "Heavy Rain", "Light Rain" ,"Overcast",	"Partly Cloudy", 
         "Mostly Cloudy	" ,"Scattered Clouds","Snow") ,  
  value=c(808171,	34315, 12064, 141073, 382480, 295439, 412528, 204662, 4796))

ggplot(Weather_data, aes(fill = name, x=name, y=value)) + 
  geom_bar(stat = "identity")



############################
#### City part data#########
############################
data_US_city <- data_drop %>% 
  select(-all_of(c("Country", "County", "Street", "Zipcode")))

dim(data_US_city)
# 2974335      33
data_CA_city <- data_US_city %>%
  separate(Start_Time, into = c("Date", "Time"), sep = " ") %>%
  mutate("Year" = str_sub(Date, 1, 4), "Month" = str_sub(Date, 6, 7), "Day" = str_sub(Date, 9, 10), 
         "Wday" = as.character(wday(Date)), "Hour" = str_sub(Time, 1, 2)) %>%
  select(-c("Date", "Time", "End_Time")) %>%
  select(TMC, Severity, Year, Month, Day, Hour, Wday, everything()) %>%
  mutate(TMC = replace_na(TMC, "NA_TMC")) %>%
  filter(!is.na(Weather_Condition)) %>%
  mutate_if(is.numeric, ~ replace_na(., mean(., na.rm = T))) %>%
  filter(State == "CA") %>% 
  select(-State)
dim(data_CA_city)
# 663204     35

glimpse(data_CA_city)

########## CITY part END #########

```

